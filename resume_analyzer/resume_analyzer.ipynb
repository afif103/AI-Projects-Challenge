{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd28abd-a963-4f86-bf25-64873b30ddde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================================================\n",
    "# AI RESUME ANALYZER — PRODUCTION-READY RAG APP\n",
    "# Author: Rami Afif\n",
    "# Stack: LangChain + Streamlit + Ollama/OpenAI + FAISS/Pinecone\n",
    "# Security: .env keys, input validation, error handling\n",
    "# =================================================\n",
    "\n",
    "import streamlit as st\n",
    "from PyPDF2 import PdfReader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings, HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS, Pinecone\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.llms import OpenAI, Ollama\n",
    "from langchain.prompts import PromptTemplate\n",
    "import os\n",
    "import re\n",
    "from dotenv import load_dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acec4639-a1a2-48fa-a83a-b4fa0968ef51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------\n",
    "# 1. LOAD SECRETS FROM .env (NEVER IN CODE!)\n",
    "# -------------------------------------------------\n",
    "load_dotenv()  # Reads .env file securely\n",
    "USE_OPENAI = os.getenv(\"USE_OPENAI\", \"false\").lower() == \"true\"\n",
    "USE_PINECONE = os.getenv(\"USE_PINECONE\", \"false\").lower() == \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3631abd-682a-4a35-9351-e3fd92699ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------\n",
    "# 2. STREAMLIT PAGE CONFIG\n",
    "# -------------------------------------------------\n",
    "st.set_page_config(page_title=\"AI Resume Analyzer\", layout=\"centered\")\n",
    "st.title(\"AI Resume Analyzer\")\n",
    "st.markdown(\"**Upload your resume (PDF) → Ask anything about it.**\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f9481d-5ba1-4b57-add8-f2f8f8e839a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------\n",
    "# 3. INPUT SAFETY FILTER (BLOCK HARMFUL INPUT)\n",
    "# -------------------------------------------------\n",
    "MAX_QUESTION_LEN = 200\n",
    "MIN_QUESTION_LEN = 3\n",
    "BLOCKED_WORDS = [\"hack\", \"jailbreak\", \"ignore\", \"system\", \"prompt\", \"bypass\", \"fuck\", \"shit\"]\n",
    "\n",
    "def is_safe_input(text: str) -> bool:\n",
    "    \"\"\"Block empty, too long, or harmful questions.\"\"\"\n",
    "    if not text or len(text.strip()) < MIN_QUESTION_LEN:\n",
    "        return False\n",
    "    if len(text) > MAX_QUESTION_LEN:\n",
    "        return False\n",
    "    if any(word in text.lower() for word in BLOCKED_WORDS):\n",
    "        return False\n",
    "    if re.search(r\"[<>(){}\\[\\]]{3,}\", text):  # Block code-like patterns\n",
    "        return False\n",
    "    return True\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df9c4dd-b8a6-4d46-aeb7-9588c7f77654",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------\n",
    "# 4. LOAD EMBEDDINGS (OpenAI or Local)\n",
    "# -------------------------------------------------\n",
    "@st.cache_resource\n",
    "def get_embeddings():\n",
    "    \"\"\"Choose between OpenAI (paid) or local (free) embeddings.\"\"\"\n",
    "    try:\n",
    "        if USE_OPENAI:\n",
    "            return OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "        return HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")  # FREE\n",
    "    except Exception as e:\n",
    "        st.error(\"Embeddings failed. Check internet or API key.\")\n",
    "        st.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f488e26-47b7-4378-8209-8e5d0e694556",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------\n",
    "# 5. LOAD LLM (OpenAI or Ollama)\n",
    "# -------------------------------------------------\n",
    "@st.cache_resource\n",
    "def get_llm():\n",
    "    \"\"\"Choose between OpenAI (fast, paid) or Ollama (free, local).\"\"\"\n",
    "    try:\n",
    "        if USE_OPENAI:\n",
    "            return OpenAI(model=\"gpt-4o-mini\", temperature=0.2)\n",
    "        return Ollama(model=\"llama3.2:3b\", temperature=0.2)  # Run `ollama pull llama3.2:3b`\n",
    "    except Exception as e:\n",
    "        st.error(\"LLM failed. Run `ollama pull llama3.2:3b` or check OpenAI key.\")\n",
    "        st.stop()\n",
    "\n",
    "embeddings = get_embeddings()\n",
    "llm = get_llm()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77503b1-02a3-4ea0-95f4-4a0181b33236",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------\n",
    "# 6. PDF UPLOAD & TEXT EXTRACTION\n",
    "# -------------------------------------------------\n",
    "uploaded_file = st.file_uploader(\"Upload Resume (PDF)\", type=\"pdf\")\n",
    "\n",
    "if uploaded_file:\n",
    "    try:\n",
    "        # Read PDF\n",
    "        reader = PdfReader(uploaded_file)\n",
    "        text = \"\"\n",
    "        for page in reader.pages:\n",
    "            page_text = page.extract_text()\n",
    "            if page_text:\n",
    "                text += page_text + \"\\n\"\n",
    "\n",
    "        if not text.strip():\n",
    "            st.error(\"No text found in PDF. Try another file.\")\n",
    "            st.stop()\n",
    "\n",
    "        # -------------------------------------------------\n",
    "        # 7. CHUNK TEXT (LangChain)\n",
    "        # -------------------------------------------------\n",
    "        splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "        docs = splitter.create_documents([text])\n",
    "\n",
    "        # -------------------------------------------------\n",
    "        # 8. CREATE VECTOR STORE (FAISS or Pinecone)\n",
    "        # -------------------------------------------------\n",
    "        with st.spinner(\"Indexing resume...\"):\n",
    "            if USE_PINECONE:\n",
    "                try:\n",
    "                    from pinecone import Pinecone as PineconeClient\n",
    "                    pc = PineconeClient(api_key=os.getenv(\"PINECONE_API_KEY\"))\n",
    "                    index_name = os.getenv(\"PINECONE_INDEX\", \"resume-index\")\n",
    "                    vectorstore = Pinecone.from_documents(docs, embeddings, index_name=index_name)\n",
    "                except Exception as e:\n",
    "                    st.warning(\"Pinecone failed. Falling back to FAISS.\")\n",
    "                    vectorstore = FAISS.from_documents(docs, embeddings)\n",
    "            else:\n",
    "                vectorstore = FAISS.from_documents(docs, embeddings)\n",
    "\n",
    "            # -------------------------------------------------\n",
    "            # 9. RETRIEVER (Get top 3 relevant chunks)\n",
    "            # -------------------------------------------------\n",
    "            retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3})\n",
    "\n",
    "            # -------------------------------------------------\n",
    "            # 10. SYSTEM PROMPT (ZERO HALLUCINATION)\n",
    "            # -------------------------------------------------\n",
    "            prompt_template = \"\"\"You are a professional HR analyst.\n",
    "            Answer ONLY using the resume text below.\n",
    "            If information is missing, say: \"Not mentioned in resume.\"\n",
    "            Be concise, factual, and professional.\n",
    "            Never reveal personal data like phone/email.\n",
    "\n",
    "            Context:\n",
    "            {context}\n",
    "\n",
    "            Question: {question}\n",
    "            Answer:\"\"\"\n",
    "\n",
    "            PROMPT = PromptTemplate(template=prompt_template, input_variables=[\"context\", \"question\"])\n",
    "\n",
    "            # -------------------------------------------------\n",
    "            # 11. RAG CHAIN (Retrieval + QA)\n",
    "            # -------------------------------------------------\n",
    "            qa = RetrievalQA.from_chain_type(\n",
    "                llm=llm,\n",
    "                chain_type=\"stuff\",\n",
    "                retriever=retriever,\n",
    "                chain_type_kwargs={\"prompt\": PROMPT},\n",
    "                return_source_documents=False,\n",
    "            )\n",
    "\n",
    "        st.success(\"Resume loaded securely!\")\n",
    "\n",
    "        # -------------------------------------------------\n",
    "        # 12. Q&A INTERFACE\n",
    "        # -------------------------------------------------\n",
    "        question = st.text_input(\n",
    "            \"Ask about your resume:\",\n",
    "            placeholder=\"What are my programming skills?\",\n",
    "            max_chars=MAX_QUESTION_LEN\n",
    "        )\n",
    "\n",
    "        if question:\n",
    "            if not is_safe_input(question):\n",
    "                st.error(\"Invalid input. Keep it short, clean, and relevant.\")\n",
    "                st.stop()\n",
    "\n",
    "            with st.spinner(\"Analyzing...\"):\n",
    "                try:\n",
    "                    answer = qa.run(question)\n",
    "                except Exception as e:\n",
    "                    st.error(\"AI failed to respond. Try again.\")\n",
    "                    st.stop()\n",
    "\n",
    "            st.markdown(\"**Answer:**\")\n",
    "            st.write(answer)\n",
    "\n",
    "            # -------------------------------------------------\n",
    "            # 13. COST TRACKING (OpenAI only)\n",
    "            # -------------------------------------------------\n",
    "            if USE_OPENAI:\n",
    "                input_tokens = len(question.split()) * 1.3\n",
    "                output_tokens = len(answer.split()) * 1.3\n",
    "                cost = (input_tokens * 0.15 + output_tokens * 0.60) / 1_000_000\n",
    "                st.caption(f\"**Estimated cost:** `${cost:.6f}` (gpt-4o-mini)\")\n",
    "\n",
    "        # -------------------------------------------------\n",
    "        # 14. SHOW CURRENT MODE\n",
    "        # -------------------------------------------------\n",
    "        mode = (\n",
    "            \"OpenAI + Pinecone\" if USE_OPENAI and USE_PINECONE else\n",
    "            \"OpenAI + FAISS\" if USE_OPENAI else\n",
    "            \"Local (Ollama + FAISS)\"\n",
    "        )\n",
    "        st.caption(f\"**Mode:** {mode} | **Security:** Active\")\n",
    "\n",
    "    except Exception as e:\n",
    "        st.error(\"Failed to process PDF. Try another file.\")\n",
    "        st.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
